{"id":485,"date":"2021-10-26T22:02:36","date_gmt":"2021-10-26T22:02:36","guid":{"rendered":"https:\/\/shichengzhang.web.illinois.edu\/?page_id=485"},"modified":"2021-10-28T01:53:21","modified_gmt":"2021-10-28T01:53:21","slug":"sonification-epilepsy-harmonization","status":"publish","type":"page","link":"https:\/\/shichengzhang.web.illinois.edu\/sonification-epilepsy-harmonization\/","title":{"rendered":"Sonification &#8211; Epilepsy Harmonizer"},"content":{"rendered":"\n<p class=\"has-medium-font-size\"><strong>Abstract:<\/strong><\/p>\n\n\n\n<p>Epilepsy Harmonization is a sonification algorithm depicting the contrast between brainwave during seizure and non-seizure. When a seizure occurs in the provided data, a series of atonal chords will be played against the tonally functional chords for non-seizure brainwaves. I set relative mean and variance thresholds on the magnitude to classify the seizure states of the given signals. (Though better to apply as a gaussian classifer) <\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Audio:<\/strong><\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"640\" height=\"480\" src=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/data.png\" alt=\"\" class=\"wp-image-661\" srcset=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/data.png 640w, https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/data-300x225.png 300w\" sizes=\"auto, (max-width: 640px) 100vw, 640px\" \/><figcaption>Fig.1A chunk of data in the UCI Epilepsy dataset with labels<\/figcaption><\/figure>\n\n\n\n<figure class=\"wp-block-audio\"><audio controls src=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/epilepsy.mp3\"><\/audio><figcaption>The sonification example for the above data<\/figcaption><\/figure>\n\n\n\n<div class=\"wp-block-file\"><a href=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/eeg_sonification_benny-1.mid\">eeg_sonification_midi<\/a><a href=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/eeg_sonification_benny-1.mid\" class=\"wp-block-file__button\" download>Download<\/a><\/div>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Description:<\/strong><\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"473\" src=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/EEG_dataset-1024x473.png\" alt=\"\" class=\"wp-image-665\" srcset=\"https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/EEG_dataset-1024x473.png 1024w, https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/EEG_dataset-300x139.png 300w, https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/EEG_dataset-768x355.png 768w, https:\/\/shichengzhang.web.illinois.edu\/wp-content\/uploads\/2021\/10\/EEG_dataset.png 1456w\" sizes=\"auto, (max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Code:<\/strong><\/p>\n\n\n\n<pre class=\"wp-block-code\"><code>\r# Musx is an algorithmic compostion framework created by Professor Heinrick Taube at UIUC \r\n# Install musx package through pip install musx \r\n\r\n# Import info and some functions are omitted, if you need source code, please contact: sz18@illinois.edu, Benny Zhang\n\r\ndef epilepsy_data_analysis(n=1780):\r\n    '''\r\n    n --> first n pt in eeg data\r\n\r\n    return a tuple (mean,std)\r\n    '''\r\n    return_list = &#91;]\r\n    sampling_rate = 178\r\n\r\n    #================================================================================\r\n    # Read epilepsy data from dataset &amp; Drop the name column and label column\r\n    df = pd.read_csv(\"epi_data\/epilepsy.csv\")\r\n    label_list = df&#91;df.columns&#91;-1]].tolist()\r\n    raw_label_list = &#91;]\r\n    #print(label_list)\r\n    for i in range(len(label_list)):\r\n        # if epilepsy then 500\r\n        if label_list&#91;i] &lt; 3:\r\n            out =  500\r\n        else:\r\n            out = -500\r\n        raw_label_list += &#91;out] * 178\r\n    #print(raw_label_list)\r\n    df = df.drop(&#91;df.columns&#91;0], df.columns&#91;-1]], axis=1)\r\n    #print(df.head())\r\n\r\n    # Convert all row into a single row\r\n    single_list = &#91;]\r\n    abs_single_list = &#91;]\r\n    for _, row in df.iterrows():\r\n        single_list += list(row)\r\n    single_list = single_list&#91;:n]\r\n    abs_single_list = &#91;abs(item) for item in single_list]&#91;:n]\r\n    #print(len(single_list))\r\n    #print(centroid)\r\n    #print(len(label_list))\r\n\r\n    #==========================================\r\n    # plot polarized graph \r\n    fig1 = plt.figure()\r\n    num = n\r\n    plt.plot(single_list&#91;:num],label=\"EEG signal\"); plt.plot(raw_label_list&#91;:num],label=\"Epilepsy Status\")\r\n    #print(single_list&#91;:2000])\r\n    plt.title(f\"EEG signal &amp; Epilepsy Status first {num} data pts\"); plt.legend()\r\n    fig1.savefig(\"data.png\")\r\n\r\n    # plot absolute value graph\r\n    fig2 = plt.figure()\r\n    plt.plot(&#91;abs(item) for item in single_list&#91;:num]],label=\"EEG signal\")\r\n    plt.plot(&#91;item + 500 for item in raw_label_list&#91;:num]],label=\"Epilepsy Status\")\r\n    \r\n    #print(single_list&#91;:2000])\r\n    plt.title(f\"abs EEG signal &amp; Epilepsy Status first {num} data pts\") ;plt.legend()\r\n    fig2.savefig(\"data_abs.png\")\r\n    #=========================================================================\r\n    print(len(label_list))\r\n\r\n    #=========================================================================\r\n    # Now we will have 2 list, mean and std\r\n    chunk_size = 20\r\n    mean = &#91;]\r\n    std = &#91;]\r\n    for i in range(int(len(single_list)\/chunk_size)):\r\n        m = np.mean(abs_single_list&#91;i*chunk_size:(i+1)*chunk_size])\r\n        s = np.std(abs_single_list&#91;i*chunk_size:(i+1)*chunk_size])\r\n        mean += &#91;m] * chunk_size\r\n        std += &#91;s] * chunk_size\r\n    print(len(mean))\r\n    print(len(std))\r\n    print(len(abs_single_list))\r\n    return (mean,std)\r\n\r\n\r\n\r\n\r\ndef eeg_sonification(mean, std, srate):\r\n\r\n    # mean is chord selection, std is the tempo rate\r\n    # mean &lt;200, 200&lt; &lt; 260, 260&lt;600, 600&lt;\r\n\r\n    consonance_level_one = &#91;&#91;60-12, 60, 64, 67], \\\r\n                            &#91;67-12, 59, 62, 67], \\\r\n                            &#91;65-12, 69-12, 60, 67]]\r\n    consonance_level_two = &#91;&#91;60-12, 60-1,62, 64, 67], \\\r\n                            &#91;67-12, 59,60, 62,65, 67], \\\r\n                            &#91;65-12, 69-12, 60,62, 67]]\r\n    dissonance_level_one = &#91;&#91;60-12, 60-1,61,62, 64, 66, 67], \\\r\n                            &#91;67-12, 59,60,61, 62,65,66, 67], \\\r\n                            &#91;65-12, 69-12, 60,61,62,66, 67]]\r\n    dissonance_level_two = &#91;&#91;60-12,58,59, 60-1,61,62, 64,65, 66, 67], \\\r\n                            &#91;67-12, 58,59,60,61, 62,64,65,66, 67], \\\r\n                            &#91;65-12, 69-12, 60,61,62,63,64,65,66, 67]]\r\n    seed_list = &#91;] # seed list is the chord for each second\r\n    srate = int(srate \/ 8)\r\n    for i in range(int(len(mean)\/(srate))):\r\n        m = np.mean(mean&#91;i*srate:(i+1)*srate])\r\n        if m &lt;= 175:\r\n            seed_list.append(0)\r\n        elif m >175 and m &lt;=230:\r\n            seed_list.append(1)\r\n        elif m > 230 and m &lt;= 400:\r\n            seed_list.append(2)\r\n        elif m > 400:\r\n            seed_list.append(3)\r\n    play_list = &#91;]\r\n    for i in range(len(seed_list)):\r\n        if seed_list&#91;i] == 0:\r\n            play_list.append(&#91;random.choice(consonance_level_one)])\r\n        elif seed_list&#91;i] == 1:\r\n            play_list.append(&#91;random.choice(consonance_level_two) for i in range(2)] )\r\n        elif seed_list&#91;i] == 2:\r\n            play_list.append(&#91;random.choice(dissonance_level_one)  for i in range(4)] )\r\n        elif seed_list&#91;i] == 3:\r\n            play_list.append(&#91;random.choice(dissonance_level_two)  for i in range(8)] )\r\n    print(play_list)\r\n    keynum_list = &#91;]\r\n    rhythm_list = &#91;]\r\n    \r\n    # initializing keynum_list\r\n    midi_event_count = 0\r\n    for i in range(len(play_list)):\r\n        for j in range(len(play_list&#91;i])):\r\n            keynum_list.append(play_list&#91;i]&#91;j])\r\n            for k in range(len(play_list&#91;i]&#91;j])):\r\n                midi_event_count +=1\r\n\r\n    # initializing rhythm_list\r\n    for i in range(len(play_list)):\r\n        if len(play_list&#91;i]) == 1:\r\n            rhythm_list += &#91;0.125]\r\n        elif len(play_list&#91;i]) == 2:\r\n            rhythm_list += &#91;0.125\/2] * 2\r\n        elif len(play_list&#91;i]) == 3:\r\n            rhythm_list += &#91;0.125\/4] * 4\r\n        elif len(play_list&#91;i]) == 4:\r\n            rhythm_list += &#91;0.125\/8] * 8\r\n\r\n    piano_pitch = keynum_list\r\n    piano_rhythm = rhythm(rhythm_list, tempo = 60)\r\n    #print(seed_list)\r\n    #print(len(seed_list))\r\n    # piano_talea = rhythm('q q q e e. e e e e e. e. e. s e e. q h', tempo=80)\r\n    # piano_color = keynum(&#91;\"f3 g bf c4 ef b e5\",  \"f3 g bf c4 e a d5\", \r\n    #                   \"f3 af bf df4 ef a d5\", \"f3 af bf df4 ef g c5\",\r\n    #                   \"f3 g bf d4 fs b c5\", \"f3 g bf d4 e a c5\",\r\n    #                   \"f3 a c4 d g cs5 fs\", \"f3 g c4 d g b e5\", \r\n    #                   \"f3 bf df4 gf e5\", \"f3 b d4 g e5 g\", \"f3 c4 ef af g5\", \r\n    #                   \"f3 cs4 e a g5 b\", \"af3 ef4 gf bf ef5 gf cf6\", \r\n    #                   \"af3 ef4 f bf df5 f5 bf5\", \"gf3 df4 af ef af cf6 ef\", \r\n    #                   \"gf3 df4 bf d5 f bf d6\", \"a3 c4 d fs bf df5 gf bf df6\", \r\n    #                   \"bf3 cs e gs c5 d gs c6\", \"c4 d f a4 cs5 e a\", \r\n    #                   \"cs4 e fs bf d5 f\", \"fs4 g bf d5 fs a\",\r\n    #                   \"fs4 a b ds5 es gs\", \"f4 bf d5 e g\", \r\n    #                   \"e4 af cs5 d\", \"d4 g b cs5 e\", \"cs4 f bf b f5\",\r\n    #                   \"b3 e4 af bf\", \"af3 cs4 f g\", \"gf3 cf4 ef f\"])\r\n    # cello_talea = rhythm('h q. h h e e q. e e e e q. e e h', tempo=80)\r\n    # cello_color = keynum('c6 e d f# bf5')\r\n     # It's good practice to add any metadata such as tempo, midi instrument\r\n    # assignments, micro tuning, etc. to track 0 in your midi file.\r\n    t0 = MidiSeq.metaseq(ins={0: AcousticGrandPiano})\r\n    # Track 1 will hold the composition.\r\n    t1 = MidiSeq()\r\n    # Create a scheduler and give it t1 as its output object.&#91;84, 88, 86, 90, 82]\r\n    q = Scheduler(t1)\r\n    # Create the piano and cello composers.\r\n    piano=brush(q, len=len(piano_pitch), rhy=piano_rhythm,\r\n                key=piano_pitch, chan=0)\r\n\r\n    # Start our composers in the scheduler, this creates the composition.\r\n    q.compose(&#91;&#91;0, piano]])\r\n    # Write a midi file with our track data.\r\n    f = MidiFile(\"eeg_sonification_benny.mid\", &#91;t0, t1]).write()\r\n    # To automatially play demos use setmidiplayer() to assign a shell\r\n    # command that will play midi files on your computer. Example:\r\n    #   setmidiplayer(\"fluidsynth -iq -g1 \/usr\/local\/sf\/MuseScore_General.sf2\")\r\n    print(f\"Wrote '{f.pathname}'.\")\r\n    playfile(f.pathname)\r\n\r\n\r\n#play_midi()\r\nsrate = 178\r\nmean, std = epilepsy_data_analysis(1780)\r\neeg_sonification(mean, std, srate)<\/code><\/pre>\n","protected":false},"excerpt":{"rendered":"<p>Abstract: Epilepsy Harmonization is a sonification algorithm depicting the contrast between brainwave during seizure and non-seizure. When a seizure occurs in the provided data, a series of atonal chords will be played against the tonally functional chords for non-seizure brainwaves. I set relative mean and variance thresholds on the magnitude to classify the seizure states&hellip; <\/p>\n","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"spay_email":"","footnotes":""},"class_list":["post-485","page","type-page","status-publish","hentry"],"_links":{"self":[{"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/pages\/485","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/comments?post=485"}],"version-history":[{"count":4,"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/pages\/485\/revisions"}],"predecessor-version":[{"id":669,"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/pages\/485\/revisions\/669"}],"wp:attachment":[{"href":"https:\/\/shichengzhang.web.illinois.edu\/wp-json\/wp\/v2\/media?parent=485"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}